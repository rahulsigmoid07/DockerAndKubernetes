[2023-06-14T09:17:15.504+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [queued]>
[2023-06-14T09:17:15.509+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [queued]>
[2023-06-14T09:17:15.510+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2023-06-14T09:17:15.510+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2023-06-14T09:17:15.511+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2023-06-14T09:17:15.518+0000] {taskinstance.py:1300} INFO - Executing <Task(PostgresOperator): insert_into_table> on 2023-06-13 00:00:00+00:00
[2023-06-14T09:17:15.521+0000] {standard_task_runner.py:55} INFO - Started process 59 to run task
[2023-06-14T09:17:15.524+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'database_postgres', 'insert_into_table', 'scheduled__2023-06-13T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/postgress_db.py', '--cfg-path', '/tmp/tmp6lnvve5k']
[2023-06-14T09:17:15.525+0000] {standard_task_runner.py:83} INFO - Job 29: Subtask insert_into_table
[2023-06-14T09:17:15.574+0000] {task_command.py:388} INFO - Running <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [running]> on host 54f992379a81
[2023-06-14T09:17:15.619+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=database_postgres
AIRFLOW_CTX_TASK_ID=insert_into_table
AIRFLOW_CTX_EXECUTION_DATE=2023-06-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-13T00:00:00+00:00
[2023-06-14T09:17:15.620+0000] {sql.py:254} INFO - Executing: INSERT INTO USERS(id,name,email,phone,address,organization) VALUES
            (1,'rahul', 'rahulksh@gmail.com','+9187345632','bihar', 'sigmoid'),
            (2,'shubham','rshuh@gmail.com','+917938535736','hyderabad','amazon'),
            (3,'pankaj','pankajksh@gmail.com','+917838895736','bihar','apple'),
            (4,'raj','rajkumar@gmail.com','+916783456890','ranchi','aidash');
[2023-06-14T09:17:15.628+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-06-14T09:17:15.725+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-06-14T09:17:15.730+0000] {sql.py:375} INFO - Running statement: INSERT INTO USERS(id,name,email,phone,address,organization) VALUES
            (1,'rahul', 'rahulksh@gmail.com','+9187345632','bihar', 'sigmoid'),
            (2,'shubham','rshuh@gmail.com','+917938535736','hyderabad','amazon'),
            (3,'pankaj','pankajksh@gmail.com','+917838895736','bihar','apple'),
            (4,'raj','rajkumar@gmail.com','+916783456890','ranchi','aidash');, parameters: None
[2023-06-14T09:17:15.732+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 266, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "users_id_key"
DETAIL:  Key (id)=(1) already exists.

[2023-06-14T09:17:15.741+0000] {taskinstance.py:1323} INFO - Marking task as FAILED. dag_id=database_postgres, task_id=insert_into_table, execution_date=20230613T000000, start_date=20230614T091715, end_date=20230614T091715
[2023-06-14T09:17:15.749+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 29 for task insert_into_table (duplicate key value violates unique constraint "users_id_key"
DETAIL:  Key (id)=(1) already exists.
; 59)
[2023-06-14T09:17:15.776+0000] {local_task_job.py:208} INFO - Task exited with return code 1
[2023-06-14T09:17:15.793+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T14:05:46.193+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [queued]>
[2023-06-14T14:05:46.198+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [queued]>
[2023-06-14T14:05:46.199+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2023-06-14T14:05:46.199+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2023-06-14T14:05:46.200+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2023-06-14T14:05:46.208+0000] {taskinstance.py:1300} INFO - Executing <Task(PostgresOperator): insert_into_table> on 2023-06-13 00:00:00+00:00
[2023-06-14T14:05:46.213+0000] {standard_task_runner.py:55} INFO - Started process 81 to run task
[2023-06-14T14:05:46.216+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'database_postgres', 'insert_into_table', 'scheduled__2023-06-13T00:00:00+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/postgress_db.py', '--cfg-path', '/tmp/tmpa3j645uz']
[2023-06-14T14:05:46.217+0000] {standard_task_runner.py:83} INFO - Job 42: Subtask insert_into_table
[2023-06-14T14:05:46.267+0000] {task_command.py:388} INFO - Running <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [running]> on host 5fd7c6d884b5
[2023-06-14T14:05:46.315+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=database_postgres
AIRFLOW_CTX_TASK_ID=insert_into_table
AIRFLOW_CTX_EXECUTION_DATE=2023-06-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-13T00:00:00+00:00
[2023-06-14T14:05:46.316+0000] {sql.py:254} INFO - Executing: INSERT INTO my_table (execution_time) VALUES (CURRENT_TIMESTAMP);
[2023-06-14T14:05:46.324+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-06-14T14:05:46.420+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-06-14T14:05:46.425+0000] {sql.py:375} INFO - Running statement: INSERT INTO my_table (execution_time) VALUES (CURRENT_TIMESTAMP);, parameters: None
[2023-06-14T14:05:46.426+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 266, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UndefinedColumn: column "execution_time" of relation "my_table" does not exist
LINE 1: INSERT INTO my_table (execution_time) VALUES (CURRENT_TIMEST...
                              ^

[2023-06-14T14:05:46.434+0000] {taskinstance.py:1323} INFO - Marking task as FAILED. dag_id=database_postgres, task_id=insert_into_table, execution_date=20230613T000000, start_date=20230614T140546, end_date=20230614T140546
[2023-06-14T14:05:46.442+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 42 for task insert_into_table (column "execution_time" of relation "my_table" does not exist
LINE 1: INSERT INTO my_table (execution_time) VALUES (CURRENT_TIMEST...
                              ^
; 81)
[2023-06-14T14:05:46.468+0000] {local_task_job.py:208} INFO - Task exited with return code 1
[2023-06-14T14:05:46.482+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T15:24:24.498+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [queued]>
[2023-06-14T15:24:24.503+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [queued]>
[2023-06-14T15:24:24.503+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2023-06-14T15:24:24.504+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2023-06-14T15:24:24.504+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2023-06-14T15:24:24.511+0000] {taskinstance.py:1300} INFO - Executing <Task(PostgresOperator): insert_into_table> on 2023-06-13 00:00:00+00:00
[2023-06-14T15:24:24.515+0000] {standard_task_runner.py:55} INFO - Started process 124 to run task
[2023-06-14T15:24:24.518+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'database_postgres', 'insert_into_table', 'scheduled__2023-06-13T00:00:00+00:00', '--job-id', '56', '--raw', '--subdir', 'DAGS_FOLDER/postgress_db.py', '--cfg-path', '/tmp/tmp7r337h1v']
[2023-06-14T15:24:24.519+0000] {standard_task_runner.py:83} INFO - Job 56: Subtask insert_into_table
[2023-06-14T15:24:24.566+0000] {task_command.py:388} INFO - Running <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [running]> on host 3de891eadda2
[2023-06-14T15:24:24.610+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=database_postgres
AIRFLOW_CTX_TASK_ID=insert_into_table
AIRFLOW_CTX_EXECUTION_DATE=2023-06-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-13T00:00:00+00:00
[2023-06-14T15:24:24.611+0000] {sql.py:254} INFO - Executing: INSERT INTO execution_table (exectime) VALUES (1,CURRENT_TIMESTAMP);
[2023-06-14T15:24:24.618+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-06-14T15:24:24.716+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-06-14T15:24:24.720+0000] {sql.py:375} INFO - Running statement: INSERT INTO execution_table (exectime) VALUES (1,CURRENT_TIMESTAMP);, parameters: None
[2023-06-14T15:24:24.722+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 266, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: INSERT has more expressions than target columns
LINE 1: INSERT INTO execution_table (exectime) VALUES (1,CURRENT_TIM...
                                                         ^

[2023-06-14T15:24:24.729+0000] {taskinstance.py:1323} INFO - Marking task as FAILED. dag_id=database_postgres, task_id=insert_into_table, execution_date=20230613T000000, start_date=20230614T152424, end_date=20230614T152424
[2023-06-14T15:24:24.736+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 56 for task insert_into_table (INSERT has more expressions than target columns
LINE 1: INSERT INTO execution_table (exectime) VALUES (1,CURRENT_TIM...
                                                         ^
; 124)
[2023-06-14T15:24:24.774+0000] {local_task_job.py:208} INFO - Task exited with return code 1
[2023-06-14T15:24:24.788+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T15:31:57.500+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [queued]>
[2023-06-14T15:31:57.506+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [queued]>
[2023-06-14T15:31:57.507+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2023-06-14T15:31:57.507+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2023-06-14T15:31:57.507+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2023-06-14T15:31:57.515+0000] {taskinstance.py:1300} INFO - Executing <Task(PostgresOperator): insert_into_table> on 2023-06-13 00:00:00+00:00
[2023-06-14T15:31:57.520+0000] {standard_task_runner.py:55} INFO - Started process 94 to run task
[2023-06-14T15:31:57.523+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'database_postgres', 'insert_into_table', 'scheduled__2023-06-13T00:00:00+00:00', '--job-id', '65', '--raw', '--subdir', 'DAGS_FOLDER/postgress_db.py', '--cfg-path', '/tmp/tmphupdmw4e']
[2023-06-14T15:31:57.524+0000] {standard_task_runner.py:83} INFO - Job 65: Subtask insert_into_table
[2023-06-14T15:31:57.574+0000] {task_command.py:388} INFO - Running <TaskInstance: database_postgres.insert_into_table scheduled__2023-06-13T00:00:00+00:00 [running]> on host 9268ba351b9c
[2023-06-14T15:31:57.621+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=database_postgres
AIRFLOW_CTX_TASK_ID=insert_into_table
AIRFLOW_CTX_EXECUTION_DATE=2023-06-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-06-13T00:00:00+00:00
[2023-06-14T15:31:57.623+0000] {sql.py:254} INFO - Executing: INSERT INTO execution_table (exectime) VALUES (CURRENT_TIMESTAMP);
[2023-06-14T15:31:57.631+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-06-14T15:31:57.742+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-06-14T15:31:57.747+0000] {sql.py:375} INFO - Running statement: INSERT INTO execution_table (exectime) VALUES (CURRENT_TIMESTAMP);, parameters: None
[2023-06-14T15:31:57.748+0000] {sql.py:384} INFO - Rows affected: 1
[2023-06-14T15:31:57.758+0000] {taskinstance.py:1323} INFO - Marking task as SUCCESS. dag_id=database_postgres, task_id=insert_into_table, execution_date=20230613T000000, start_date=20230614T153157, end_date=20230614T153157
[2023-06-14T15:31:57.816+0000] {local_task_job.py:208} INFO - Task exited with return code 0
[2023-06-14T15:31:57.830+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
